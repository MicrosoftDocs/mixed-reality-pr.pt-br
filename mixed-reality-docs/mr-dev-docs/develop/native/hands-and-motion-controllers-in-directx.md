---
title: Controladores de mãos e emovimento no DirectX
description: Introdução ao guia do desenvolvedor para usar os controladores de rastreamento e movimentação em aplicativos nativos do DirectX.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 08/04/2020
ms.topic: article
keywords: mãos, controladores de movimento, DirectX, entrada, hologramas, headset de realidade misturada, headset de realidade mista do Windows, headset da realidade virtual
ms.openlocfilehash: 2f14cb06e440787bbd6541a05a983e0614293727
ms.sourcegitcommit: 63b7f6d5237327adc51486afcd92424b79e6118b
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 01/26/2021
ms.locfileid: "98810165"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="9e2d9-104">Controladores de mãos e emovimento no DirectX</span><span class="sxs-lookup"><span data-stu-id="9e2d9-104">Hands and motion controllers in DirectX</span></span>

> [!NOTE]
> <span data-ttu-id="9e2d9-105">Este artigo está relacionado às APIs nativas do WinRT herdadas.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-105">This article relates to the legacy WinRT native APIs.</span></span>  <span data-ttu-id="9e2d9-106">Para novos projetos de aplicativos nativos, é recomendável usar a **[API OpenXR](openxr-getting-started.md)**.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-106">For new native app projects, we recommend using the **[OpenXR API](openxr-getting-started.md)**.</span></span>

<span data-ttu-id="9e2d9-107">No Windows Mixed Reality, a entrada do [controlador de movimento](../../design/motion-controllers.md) e a mão são manipuladas por meio de APIs de entrada espaciais, encontradas no namespace [Windows. UI. Input. espacial](/uwp/api/windows.ui.input.spatial) .</span><span class="sxs-lookup"><span data-stu-id="9e2d9-107">In Windows Mixed Reality, both hand and [motion controller](../../design/motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="9e2d9-108">Isso permite que você manipule facilmente ações comuns, como **Select** , da mesma maneira em ambos os controladores de mãos e de movimento.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-108">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="9e2d9-109">Introdução</span><span class="sxs-lookup"><span data-stu-id="9e2d9-109">Getting started</span></span>

<span data-ttu-id="9e2d9-110">Para acessar a entrada espacial na realidade mista do Windows, comece com a interface SpatialInteractionManager.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-110">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="9e2d9-111">Você pode acessar essa interface chamando  [SpatialInteractionManager:: GetForCurrentView](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), normalmente durante a inicialização do aplicativo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-111">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="9e2d9-112">O trabalho do SpatialInteractionManager é fornecer acesso ao [SpatialInteractionSources](/uwp/api/windows.ui.input.spatial.spatialinteractionsource), que representa uma fonte de entrada.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-112">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](/uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="9e2d9-113">Há três tipos de SpatialInteractionSources disponíveis no sistema.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-113">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="9e2d9-114">A **mão** representa a mão detectada do usuário.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-114">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="9e2d9-115">As fontes de mão oferecem diferentes recursos com base no dispositivo, variando de gestos básicos no HoloLens até o controle de mão totalmente articulado no HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-115">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="9e2d9-116">O **controlador** representa um controlador de movimento emparelhado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-116">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="9e2d9-117">Os controladores de movimento podem oferecer recursos diferentes, por exemplo, selecionar gatilhos, botões de menu, botões de compreensão, touchpads e Thumbsticks.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-117">Motion controllers can offer different capabilities, for example, Select triggers, Menu buttons, Grasp buttons, touchpads, and thumbsticks.</span></span>
* <span data-ttu-id="9e2d9-118">**Voz** representa as palavras-chave detectadas pelo sistema de fala de voz do usuário.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-118">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="9e2d9-119">Por exemplo, essa fonte injetará uma prensa e uma liberação Select sempre que o usuário disser "Select".</span><span class="sxs-lookup"><span data-stu-id="9e2d9-119">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="9e2d9-120">Os dados por quadro de uma fonte são representados pela interface  [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) .</span><span class="sxs-lookup"><span data-stu-id="9e2d9-120">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="9e2d9-121">Há duas maneiras diferentes de acessar esses dados, dependendo se você deseja usar um modelo controlado por eventos ou baseado em sondagem em seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-121">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="9e2d9-122">Entrada orientada por evento</span><span class="sxs-lookup"><span data-stu-id="9e2d9-122">Event-driven input</span></span>
<span data-ttu-id="9e2d9-123">O SpatialInteractionManager fornece vários eventos que seu aplicativo pode escutar.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-123">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="9e2d9-124">Alguns exemplos incluem   [SourcePressed](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased e [SourceUpdated](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-124">A few examples include   [SourcePressed](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased, and [SourceUpdated](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="9e2d9-125">Por exemplo, o código a seguir conecta um manipulador de eventos chamado MyApp:: OnSourcePressed ao evento SourcePressed.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-125">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="9e2d9-126">Isso permite que seu aplicativo detecte pressionamentos em qualquer tipo de fonte de interação.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-126">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="9e2d9-127">Esse evento pressionado é enviado para seu aplicativo de forma assíncrona, junto com o SpatialInteractionSourceState correspondente no momento em que a ocorrência ocorreu.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-127">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="9e2d9-128">Seu aplicativo ou mecanismo de jogo pode querer iniciar o processamento imediatamente ou colocar os dados de evento em fila na rotina de processamento de entrada.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-128">Your app or game engine may want to start processing right away or queue up the event data in your input processing routine.</span></span> <span data-ttu-id="9e2d9-129">Aqui está uma função de manipulador de eventos para o evento SourcePressed, que verifica se o botão de seleção foi pressionado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-129">Here's an event handler function for the SourcePressed event, which checks whether the select button has been pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="9e2d9-130">O código acima verifica apenas a prensa ' Select ', que corresponde à ação principal no dispositivo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-130">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="9e2d9-131">Os exemplos incluem fazer um AirTap no HoloLens ou extrair o gatilho em um controlador de movimento.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-131">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="9e2d9-132">"Select" Presss representam a intenção do usuário de ativar o holograma que eles estão direcionando.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-132">'Select' presses represent the user's intention to activate the hologram they're targeting.</span></span>  <span data-ttu-id="9e2d9-133">O evento SourcePressed será acionado para vários botões e gestos diferentes, e você poderá inspecionar outras propriedades no SpatialInteractionSource para testar esses casos.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-133">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="9e2d9-134">Entrada baseada em sondagem</span><span class="sxs-lookup"><span data-stu-id="9e2d9-134">Polling-based input</span></span>
<span data-ttu-id="9e2d9-135">Você também pode usar SpatialInteractionManager para sondar o estado atual de entrada de cada quadro.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-135">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="9e2d9-136">Para fazer isso, chame [GetDetectedSourcesAtTimestamp](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) todos os quadros.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-136">To do this, call [GetDetectedSourcesAtTimestamp](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="9e2d9-137">Essa função retorna uma matriz que contém um [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) para cada [SpatialInteractionSource](/uwp/api/windows.ui.input.spatial.spatialinteractionsource)ativo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-137">This function returns an array containing one [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="9e2d9-138">Isso significa que um para cada controlador de movimento ativo, um para cada mão controlada e outro para fala se um comando ' Select ' foi recentemente desmarcado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-138">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="9e2d9-139">Em seguida, você pode inspecionar as propriedades em cada SpatialInteractionSourceState para direcionar a entrada para o seu aplicativo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-139">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="9e2d9-140">Aqui está um exemplo de como verificar a ação ' Select ' usando o método de sondagem.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-140">Here's an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="9e2d9-141">A variável de *previsão* representa um objeto [HolographicFramePrediction](/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) , que pode ser obtido do [HolographicFrame](/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-141">The *prediction* variable represents a [HolographicFramePrediction](/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](/uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="9e2d9-142">Cada SpatialInteractionSource tem uma ID, que pode ser usada para identificar novas fontes e correlacionar as fontes existentes do quadro ao quadro.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-142">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="9e2d9-143">As mãos recebem uma nova ID toda vez que deixam e inserem o FOV, mas as IDs do controlador permanecem estáticas durante a sessão.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-143">Hands get a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="9e2d9-144">Você pode usar os eventos em SpatialInteractionManager, como [SourceDetected](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) e [SourceLost](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), para reagir quando as mãos entrarem ou saírem do modo de exibição do dispositivo ou quando os controladores de movimento estiverem ativados ou desligados ou estiverem emparelhados/não emparelhados.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-144">You can use the events on SpatialInteractionManager such as [SourceDetected](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="9e2d9-145">Previstos versus histórico de poses</span><span class="sxs-lookup"><span data-stu-id="9e2d9-145">Predicted vs. historical poses</span></span>
<span data-ttu-id="9e2d9-146">GetDetectedSourcesAtTimestamp tem um parâmetro timestamp.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-146">GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="9e2d9-147">Isso permite solicitar o estado e representar os dados que são previstos ou históricos, permitindo que você correlacione as interações espaciais com outras fontes de entrada.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-147">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="9e2d9-148">Por exemplo, ao renderizar a posição da mão no quadro atual, você pode passar o carimbo de data/hora previsto fornecido pelo [HolographicFrame](/uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-148">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](/uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="9e2d9-149">Isso permite que o sistema faça uma previsão antecipada da posição da mão para alinhar fortemente com a saída do quadro renderizado, minimizando a latência percebida.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-149">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="9e2d9-150">No entanto, tal pose prevista não produz um apontador ideal para direcionar com uma fonte de interação.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-150">However, such a predicted pose doesn't produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="9e2d9-151">Por exemplo, quando um botão de controlador de movimento é pressionado, pode levar até 20 ms para que esse evento seja emergido por meio do Bluetooth para o sistema operacional.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-151">For example, when a motion controller button is pressed, it can take up to 20 ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="9e2d9-152">Da mesma forma, depois que um usuário faz um gesto de mão, uma quantidade de tempo pode passar antes que o sistema detecte o gesto e seu aplicativo o sonda para ele.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-152">Similarly, after a user does a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="9e2d9-153">Quando o aplicativo sonda uma alteração de estado, a cabeça e a mão são usadas para direcionar essa interação realmente ocorrida no passado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-153">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="9e2d9-154">Se você se destinar passando o carimbo de data/hora atual do HolographicFrame para GetDetectedSourcesAtTimestamp, a pose será encaminhada prevista para o destino Ray no momento em que o quadro será exibido, o que poderia ser mais de 20 ms no futuro.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-154">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20 ms in the future.</span></span> <span data-ttu-id="9e2d9-155">Essa futura pose é boa para *renderizar* a origem da interação, mas aumenta nosso problema de tempo para *direcionar* a interação, já que o direcionamento do usuário ocorreu no passado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-155">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="9e2d9-156">Felizmente, os eventos [SourcePressed](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased e [SourceUpdated](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) fornecem o [estado](/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) histórico associado a cada evento de entrada.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-156">Fortunately, the [SourcePressed](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased, and [SourceUpdated](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="9e2d9-157">Isso inclui diretamente o cabeçalho histórico e as poses de mão disponíveis por meio de [TryGetPointerPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), juntamente com um [carimbo de data/hora](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) histórico que você pode passar para outras APIs para correlacionar com esse evento.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-157">This directly includes the historical head and hand poses available through [TryGetPointerPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="9e2d9-158">Isso leva às seguintes práticas recomendadas ao renderizar e direcionar com mãos e controladores a cada quadro:</span><span class="sxs-lookup"><span data-stu-id="9e2d9-158">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="9e2d9-159">Para **renderização à mão/controlador** em cada quadro, seu aplicativo deve **sondar** a pose **previsível** de cada fonte de interação na hora do Photon do quadro atual.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-159">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="9e2d9-160">Você pode sondar todas as fontes de interação chamando [GetDetectedSourcesAtTimestamp](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) a cada quadro, passando o carimbo de data/hora previsto fornecido por [HolographicFrame:: CurrentPrediction](/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-160">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="9e2d9-161">Para **direcionamento à mão/controlador** em um Press ou Release, seu aplicativo deve lidar com **eventos** prensados/liberados, raycasting com base na cabeça **histórica** ou na pose do evento.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-161">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="9e2d9-162">Você obtém esse destino Ray manipulando o evento [SourcePressed](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) ou [SourceReleased](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) , obtendo a propriedade [State](/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) dos argumentos do evento e, em seguida, chamando seu método [TryGetPointerPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) .</span><span class="sxs-lookup"><span data-stu-id="9e2d9-162">You get this targeting ray by handling the [SourcePressed](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="9e2d9-163">Propriedades de entrada de dispositivo cruzado</span><span class="sxs-lookup"><span data-stu-id="9e2d9-163">Cross-device input properties</span></span>
<span data-ttu-id="9e2d9-164">A API do SpatialInteractionSource dá suporte a controladores e sistemas de acompanhamento de mão com uma ampla gama de recursos.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-164">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="9e2d9-165">Vários desses recursos são comuns entre os tipos de dispositivo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-165">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="9e2d9-166">Por exemplo, o rastreamento de mão e os controladores de movimento fornecem uma ação ' Select ' e uma posição 3D.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-166">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="9e2d9-167">Sempre que possível, a API mapeia esses recursos comuns para as mesmas propriedades no SpatialInteractionSource.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-167">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="9e2d9-168">Isso permite que os aplicativos ofereçam suporte mais facilmente a uma ampla gama de tipos de entrada.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-168">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="9e2d9-169">A tabela a seguir descreve as propriedades com suporte e como elas são comparadas entre os tipos de entrada.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-169">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="9e2d9-170">Propriedade</span><span class="sxs-lookup"><span data-stu-id="9e2d9-170">Property</span></span> | <span data-ttu-id="9e2d9-171">Descrição</span><span class="sxs-lookup"><span data-stu-id="9e2d9-171">Description</span></span> | <span data-ttu-id="9e2d9-172">Gestos de HoloLens (1º gen)</span><span class="sxs-lookup"><span data-stu-id="9e2d9-172">HoloLens(1st gen) Gestures</span></span> | <span data-ttu-id="9e2d9-173">Controladores de movimento</span><span class="sxs-lookup"><span data-stu-id="9e2d9-173">Motion Controllers</span></span> | <span data-ttu-id="9e2d9-174">Mãos articuladas</span><span class="sxs-lookup"><span data-stu-id="9e2d9-174">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="9e2d9-175">SpatialInteractionSource::**destro/canhoto**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-175">SpatialInteractionSource::**Handedness**</span></span>](/uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="9e2d9-176">À direita ou à esquerda/controlador.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-176">Right or left hand / controller.</span></span> | <span data-ttu-id="9e2d9-177">Sem suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-177">Not Supported</span></span> | <span data-ttu-id="9e2d9-178">Com suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-178">Supported</span></span> | <span data-ttu-id="9e2d9-179">Com suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-179">Supported</span></span> |
| [<span data-ttu-id="9e2d9-180">SpatialInteractionSourceState::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-180">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="9e2d9-181">Estado atual do botão primário.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-181">Current state of the primary button.</span></span> | <span data-ttu-id="9e2d9-182">Toque de ar</span><span class="sxs-lookup"><span data-stu-id="9e2d9-182">Air Tap</span></span> | <span data-ttu-id="9e2d9-183">Gatilho</span><span class="sxs-lookup"><span data-stu-id="9e2d9-183">Trigger</span></span> | <span data-ttu-id="9e2d9-184">Toque de ar relaxado (pinçagem vertical)</span><span class="sxs-lookup"><span data-stu-id="9e2d9-184">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="9e2d9-185">SpatialInteractionSourceState::**Issegured**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-185">SpatialInteractionSourceState::**IsGrasped**</span></span>](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="9e2d9-186">Estado atual do botão de captura.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-186">Current state of the grab button.</span></span> | <span data-ttu-id="9e2d9-187">Sem suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-187">Not Supported</span></span> | <span data-ttu-id="9e2d9-188">Botão de captura</span><span class="sxs-lookup"><span data-stu-id="9e2d9-188">Grab button</span></span> | <span data-ttu-id="9e2d9-189">Apertar ou fechar mão</span><span class="sxs-lookup"><span data-stu-id="9e2d9-189">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="9e2d9-190">SpatialInteractionSourceState::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-190">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="9e2d9-191">Estado atual do botão de menu.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-191">Current state of the menu button.</span></span>    | <span data-ttu-id="9e2d9-192">Sem suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-192">Not Supported</span></span> | <span data-ttu-id="9e2d9-193">Botão de menu</span><span class="sxs-lookup"><span data-stu-id="9e2d9-193">Menu Button</span></span> | <span data-ttu-id="9e2d9-194">Sem suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-194">Not Supported</span></span> |
| [<span data-ttu-id="9e2d9-195">SpatialInteractionSourceLocation::**Position**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-195">SpatialInteractionSourceLocation::**Position**</span></span>](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="9e2d9-196">Local XYZ da posição da mão ou de alças no controlador.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-196">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="9e2d9-197">Local do Palm</span><span class="sxs-lookup"><span data-stu-id="9e2d9-197">Palm location</span></span> | <span data-ttu-id="9e2d9-198">Segurar posição de pose</span><span class="sxs-lookup"><span data-stu-id="9e2d9-198">Grip pose position</span></span> | <span data-ttu-id="9e2d9-199">Local do Palm</span><span class="sxs-lookup"><span data-stu-id="9e2d9-199">Palm location</span></span> |
| [<span data-ttu-id="9e2d9-200">SpatialInteractionSourceLocation::**Orientation**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-200">SpatialInteractionSourceLocation::**Orientation**</span></span>](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="9e2d9-201">Quaternion representando a orientação da posição de mão ou de alça no controlador.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-201">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="9e2d9-202">Sem suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-202">Not Supported</span></span> | <span data-ttu-id="9e2d9-203">Segure a orientação da pose</span><span class="sxs-lookup"><span data-stu-id="9e2d9-203">Grip pose orientation</span></span> | <span data-ttu-id="9e2d9-204">Orientação de Palm</span><span class="sxs-lookup"><span data-stu-id="9e2d9-204">Palm orientation</span></span> |
| [<span data-ttu-id="9e2d9-205">SpatialPointerInteractionSourcePose::**Position**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-205">SpatialPointerInteractionSourcePose::**Position**</span></span>](/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="9e2d9-206">Origem do raio de apontar.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-206">Origin of the pointing ray.</span></span> | <span data-ttu-id="9e2d9-207">Sem suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-207">Not Supported</span></span> | <span data-ttu-id="9e2d9-208">Com suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-208">Supported</span></span> | <span data-ttu-id="9e2d9-209">Com suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-209">Supported</span></span> |
| [<span data-ttu-id="9e2d9-210">SpatialPointerInteractionSourcePose::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="9e2d9-210">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="9e2d9-211">Direção do raio de apontar.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-211">Direction of the pointing ray.</span></span> | <span data-ttu-id="9e2d9-212">Sem suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-212">Not Supported</span></span> | <span data-ttu-id="9e2d9-213">Com suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-213">Supported</span></span> | <span data-ttu-id="9e2d9-214">Com suporte</span><span class="sxs-lookup"><span data-stu-id="9e2d9-214">Supported</span></span> |

<span data-ttu-id="9e2d9-215">Algumas das propriedades acima não estão disponíveis em todos os dispositivos, e a API fornece um meio de testar isso.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-215">Some of the above properties aren't available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="9e2d9-216">Por exemplo, você pode inspecionar a propriedade [SpatialInteractionSource:: IsGraspSupported](/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) para determinar se a origem fornece uma ação de compreensão.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-216">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="9e2d9-217">Segurar pose vs. ponto de apontar</span><span class="sxs-lookup"><span data-stu-id="9e2d9-217">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="9e2d9-218">O Windows Mixed Reality dá suporte a controladores de movimento em diferentes fatores forma.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-218">Windows Mixed Reality supports motion controllers in different form factors.</span></span>  <span data-ttu-id="9e2d9-219">Ele também dá suporte a sistemas de controle de mão articulados.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-219">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="9e2d9-220">Todos esses sistemas têm diferentes relações entre a posição da mão e a direção natural "encaminhar" que os aplicativos devem usar para apontar ou renderizar objetos na mão do usuário.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-220">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendering objects in the user's hand.</span></span>  <span data-ttu-id="9e2d9-221">Para dar suporte a tudo isso, há dois tipos de poses 3D fornecidos para os controladores de rastreamento e de movimento à mão.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-221">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="9e2d9-222">A primeira é Segure pose, que representa a posição da mão do usuário.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-222">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="9e2d9-223">A segunda é a pose de ponto, que representa um ponteiro de raio originário da mão do usuário ou do controlador.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-223">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="9e2d9-224">Portanto, se você quiser renderizar **a mão do usuário** ou **um objeto mantido na mão do usuário**, como uma gumes ou uma arma, use a pose de alça.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-224">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="9e2d9-225">Se você quiser Raycast a partir do controlador ou da mão, por exemplo, quando o usuário for \* \* apontando para a interface do usuário, use a pose de ponteiro.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-225">If you want to raycast from the controller or hand, for example when the user is \*\*pointing at UI, use the pointing pose.</span></span>

<span data-ttu-id="9e2d9-226">Você pode acessar a **alça de pose** por meio de [SpatialInteractionSourceState::P Propriedades:: TryGetLocation (...)](/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_). Ele é definido da seguinte maneira:</span><span class="sxs-lookup"><span data-stu-id="9e2d9-226">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_). It's defined as follows:</span></span>
* <span data-ttu-id="9e2d9-227">A **posição de alça**: o Palm centróide ao manter o controlador naturalmente, ajustado para a esquerda ou para a direita para centralizar a posição dentro da alça.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-227">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="9e2d9-228">O **eixo direito da orientação de alça**: quando você abre completamente a mão para formar uma pose plana de 5 dedos, o raio normal para o Palm (para frente do Palm esquerdo, para trás do Palm direito)</span><span class="sxs-lookup"><span data-stu-id="9e2d9-228">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="9e2d9-229">O **eixo de encaminhamento da orientação de alça**: quando você fecha a sua mão parcialmente (como se você mantiver o controlador), o raio que aponta para "encaminhar" por meio do tubo formado por seus dedos não-thumbs.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-229">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="9e2d9-230">O **eixo superior da orientação de alça**: o eixo superior implícito pelas definições direita e avançar.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-230">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="9e2d9-231">Você pode acessar o **ponteiro de pose** por meio de [SpatialInteractionSourceState::P Propriedades:: TryGetLocation (...):: SourcePointerPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) ou [SpatialInteractionSourceState:: TryGetPointerPose (...):: TryGetInteractionSourcePose](/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-231">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="9e2d9-232">Propriedades de entrada específicas do controlador</span><span class="sxs-lookup"><span data-stu-id="9e2d9-232">Controller-specific input properties</span></span>
<span data-ttu-id="9e2d9-233">Para controladores, o SpatialInteractionSource tem uma propriedade de controlador com recursos adicionais.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-233">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="9e2d9-234">**HasThumbstick:** Se for true, o controlador terá um Thumbstick.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-234">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="9e2d9-235">Inspecione a propriedade [controllerproperties](/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) do SpatialInteractionSourceState para adquirir os valores x e y de Thumbstick (ThumbstickX e ThumbstickY), bem como seu estado pressionado (IsThumbstickPressed).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-235">Inspect the [ControllerProperties](/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="9e2d9-236">**HasTouchpad:** Se for true, o controlador terá um touchpad.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-236">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="9e2d9-237">Inspecione a propriedade Controllerproperties do SpatialInteractionSourceState para adquirir os valores x e y do Touchpad (TouchpadX e touchpad) e para saber se o usuário está tocando no Pad (IsTouchpadTouched) e se ele está pressionando o touchpad (IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-237">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they're pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="9e2d9-238">**SimpleHapticsController:** A API do SimpleHapticsController para o controlador permite inspecionar os recursos do haptics do controlador e também permite que você controle os comentários do Haptic.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-238">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="9e2d9-239">O intervalo para Touchpad e Thumbstick é de-1 a 1 para ambos os eixos (de baixo para cima e da esquerda para a direita).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-239">The range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="9e2d9-240">O intervalo para o gatilho analógico, que é acessado usando a propriedade SpatialInteractionSourceState:: SelectPressedValue, tem um intervalo de 0 a 1.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-240">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="9e2d9-241">Um valor de 1 se correlaciona com IsSelectPressed sendo igual a true; qualquer outro valor se correlaciona com IsSelectPressed sendo igual a false.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-241">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="9e2d9-242">Acompanhamento de mão articulada</span><span class="sxs-lookup"><span data-stu-id="9e2d9-242">Articulated hand tracking</span></span>
<span data-ttu-id="9e2d9-243">A API do Windows Mixed Reality fornece suporte completo para acompanhamento de mão articulada, por exemplo, no HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-243">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="9e2d9-244">O controle de mão articulado pode ser usado para implementar a manipulação direta e modelos de entrada de ponto e confirmação em seus aplicativos.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-244">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="9e2d9-245">Ele também pode ser usado para criar interações totalmente personalizadas.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-245">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="9e2d9-246">Esqueleto da mão</span><span class="sxs-lookup"><span data-stu-id="9e2d9-246">Hand skeleton</span></span>
<span data-ttu-id="9e2d9-247">O controle de mão articulado fornece um esqueleto de 25 conjunta que permite muitos tipos diferentes de interações.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-247">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="9e2d9-248">O esqueleto fornece cinco junções para o índice/meio/anel/pequenos dedos, quatro junções para o Thumb e uma junta de pulso.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-248">The skeleton provides five joints for the index/middle/ring/little fingers, four joints for the thumb, and one wrist joint.</span></span>  <span data-ttu-id="9e2d9-249">A junta do pulso serve como a base da hierarquia.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-249">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="9e2d9-250">A figura a seguir ilustra o layout do esqueleto.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-250">The following picture illustrates the layout of the skeleton.</span></span>

![Esqueleto da mão](images/hand-skeleton.png)

<span data-ttu-id="9e2d9-252">Na maioria dos casos, cada conjunto é nomeado com base no Bone que ele representa.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-252">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="9e2d9-253">Como há dois Bones em cada conjunto, usamos uma Convenção de nomear cada conjunto com base no Bone filho nesse local.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-253">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="9e2d9-254">O Bone filho é definido como o Bone além do pulso.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-254">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="9e2d9-255">Por exemplo, a junção "index proximal" contém a posição inicial do proximal Bone do índice e a orientação desse Bone.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-255">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="9e2d9-256">Ele não contém a posição final do Bone.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-256">It doesn't contain the ending position of the bone.</span></span>  <span data-ttu-id="9e2d9-257">Se precisar disso, você o obteria do próximo conjunto na hierarquia, a junção de "índice intermediário".</span><span class="sxs-lookup"><span data-stu-id="9e2d9-257">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="9e2d9-258">Além das 25 junções hierárquicas, o sistema fornece um conjunto de Palm.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-258">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="9e2d9-259">A Palm normalmente não é considerada parte da estrutura estrutural.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-259">The palm isn't typically considered part of the skeletal structure.</span></span> <span data-ttu-id="9e2d9-260">Ele é fornecido apenas como uma maneira conveniente de obter a posição e a orientação gerais do manual.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-260">It's provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="9e2d9-261">As informações a seguir são fornecidas para cada conjunto:</span><span class="sxs-lookup"><span data-stu-id="9e2d9-261">The following information is provided for each joint:</span></span>

| <span data-ttu-id="9e2d9-262">Nome</span><span class="sxs-lookup"><span data-stu-id="9e2d9-262">Name</span></span> | <span data-ttu-id="9e2d9-263">Descrição</span><span class="sxs-lookup"><span data-stu-id="9e2d9-263">Description</span></span> |
|--- |--- |
|<span data-ttu-id="9e2d9-264">Posição</span><span class="sxs-lookup"><span data-stu-id="9e2d9-264">Position</span></span> | <span data-ttu-id="9e2d9-265">posição 3D da junção, disponível em qualquer sistema de coordenadas solicitado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-265">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="9e2d9-266">Orientation</span><span class="sxs-lookup"><span data-stu-id="9e2d9-266">Orientation</span></span> | <span data-ttu-id="9e2d9-267">orientação 3D do Bone, disponível em qualquer sistema de coordenadas solicitado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-267">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="9e2d9-268">Raio</span><span class="sxs-lookup"><span data-stu-id="9e2d9-268">Radius</span></span> | <span data-ttu-id="9e2d9-269">Distância da superfície da capa na posição conjunta.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-269">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="9e2d9-270">Útil para ajustar interações diretas ou visualizações que dependem da largura do dedo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-270">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="9e2d9-271">Precisão</span><span class="sxs-lookup"><span data-stu-id="9e2d9-271">Accuracy</span></span> | <span data-ttu-id="9e2d9-272">Fornece uma dica sobre a confiança do sistema sobre as informações deste conjunto.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-272">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="9e2d9-273">Você pode acessar os dados de esqueleto da mão por meio de uma função no [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-273">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="9e2d9-274">A função é chamada de [TryGetHandPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose)e retorna um objeto chamado [HandPose](/uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-274">The function is called [TryGetHandPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](/uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="9e2d9-275">Se a origem não der suporte a mãos articuladas, essa função retornará NULL.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-275">If the source doesn't support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="9e2d9-276">Depois de ter um HandPose, você pode obter os dados concorrentes atuais chamando [TryGetJoint](/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), com o nome da junção em que você está interessado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-276">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you're interested in.</span></span>  <span data-ttu-id="9e2d9-277">Os dados são retornados como uma estrutura [JointPose](/uwp/api/windows.perception.people.jointpose) .</span><span class="sxs-lookup"><span data-stu-id="9e2d9-277">The data is returned as a [JointPose](/uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="9e2d9-278">O código a seguir obtém a posição da dica de dedo do índice.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-278">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="9e2d9-279">A variável *CurrentState* representa uma instância de [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-279">The variable *currentState* represents an instance of [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="9e2d9-280">Malha à mão</span><span class="sxs-lookup"><span data-stu-id="9e2d9-280">Hand mesh</span></span>

<span data-ttu-id="9e2d9-281">A API de acompanhamento de mão articulada permite uma malha à mão do triângulo totalmente reformado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-281">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="9e2d9-282">Essa malha pode Deform em tempo real junto com o esqueleto da mão e é útil para visualização e técnicas de física avançadas.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-282">This mesh can deform in real time along with the hand skeleton, and is useful for visualization and advanced physics techniques.</span></span>  <span data-ttu-id="9e2d9-283">Para acessar a malha à mão, primeiro você precisa criar um objeto [HandMeshObserver](/uwp/api/windows.perception.people.handmeshobserver) chamando [TryCreateHandMeshObserverAsync](/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) no [SpatialInteractionSource](/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-283">To access the hand mesh, you need to first create a [HandMeshObserver](/uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="9e2d9-284">Isso só precisa ser feito uma vez por fonte, normalmente na primeira vez que você o vê.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-284">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="9e2d9-285">Isso significa que você chamará essa função para criar um objeto HandMeshObserver sempre que uma mão inserir o FOV.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-285">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="9e2d9-286">Essa é uma função assíncrona, portanto, você terá que lidar com um pouco de simultaneidade aqui.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-286">This is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="9e2d9-287">Uma vez disponível, você pode solicitar ao objeto HandMeshObserver para o buffer de índice de triângulo chamando [GetTriangleIndices](/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-287">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="9e2d9-288">Os índices não alteram o quadro no quadro, para que você possa obtê-los uma vez e armazená-los em cache durante o tempo de vida da origem.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-288">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="9e2d9-289">Os índices são fornecidos na ordem de enrolamento no sentido horário.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-289">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="9e2d9-290">O código a seguir gira um std:: thread desanexado para criar o observador de malha e extrai o buffer de índice quando o observador de malha está disponível.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-290">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="9e2d9-291">Ele começa com uma variável chamada *CurrentState*, que é uma instância de [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) que representa uma mão controlada.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-291">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="9e2d9-292">Iniciar um thread desanexado é apenas uma opção para lidar com chamadas assíncronas.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-292">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="9e2d9-293">Como alternativa, você pode usar a nova funcionalidade de [co_await](/windows/uwp/cpp-and-winrt-apis/concurrency) com suporte do C++/WinRT.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-293">Alternatively, you could use the new [co_await](/windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="9e2d9-294">Depois de ter um objeto HandMeshObserver, você deve mantê-lo durante a duração em que seu SpatialInteractionSource correspondente está ativo.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-294">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="9e2d9-295">Em seguida, cada quadro pode ser solicitado para o último buffer de vértice que representa a mão chamando [GetVertexStateForPose](/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) e passando uma instância [HandPose](/uwp/api/windows.perception.people.handpose) que represente a pose para a qual você deseja vértices.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-295">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](/uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="9e2d9-296">Cada vértice no buffer tem uma posição e um normal.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-296">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="9e2d9-297">Aqui está um exemplo de como obter o conjunto atual de vértices para uma malha à mão.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-297">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="9e2d9-298">Como antes, a variável *CurrentState* representa uma instância de [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-298">As before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="9e2d9-299">Ao contrário das junções de esqueleto, a API de malha à mão não permite que você especifique um sistema de coordenadas para os vértices.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-299">In contrast to skeleton joints, the hand mesh API doesn't allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="9e2d9-300">Em vez disso, o [HandMeshVertexState](/uwp/api/windows.perception.people.handmeshvertexstate) especifica o sistema de coordenadas no qual os vértices são fornecidos.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-300">Instead, the [HandMeshVertexState](/uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="9e2d9-301">Em seguida, você pode obter uma transformação de malha chamando [TryGetTransformTo](/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) e especificando o sistema de coordenadas desejado.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-301">You can then get a mesh transform by calling [TryGetTransformTo](/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying the coordinate system you want.</span></span>  <span data-ttu-id="9e2d9-302">Você precisará usar essa transformação de malha sempre que trabalhar com os vértices.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-302">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="9e2d9-303">Essa abordagem reduz a sobrecarga da CPU, especialmente se você estiver usando apenas a malha para fins de processamento.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-303">This approach reduces CPU overhead, especially if you're only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="9e2d9-304">Gestos de composição olhar e Commit</span><span class="sxs-lookup"><span data-stu-id="9e2d9-304">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="9e2d9-305">Para aplicativos que usam o modelo de entrada olhar-and-Commit, especialmente no HoloLens (primeira gen), a API de entrada espacial fornece um [SpatialGestureRecognizer](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) opcional que pode ser usado para habilitar gestos compostos criados sobre o evento ' Select '.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-305">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) that can be used to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="9e2d9-306">Ao rotear interações do SpatialInteractionManager para o SpatialGestureRecognizer de um holograma, os aplicativos podem detectar eventos de toque, retenção, manipulação e navegação uniformemente entre dispositivos de entrada de teclado, de voz e espaciais, sem a necessidade de lidar manualmente com os pressionamentos e as versões.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-306">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="9e2d9-307">SpatialGestureRecognizer faz apenas a Desambigüidade mínima entre o conjunto de gestos que você solicita.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-307">SpatialGestureRecognizer does only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="9e2d9-308">Por exemplo, se você solicitar apenas o toque, o usuário poderá manter seu dedo no mesmo tempo que desejar e um toque ainda ocorrerá.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-308">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="9e2d9-309">Se você solicitar tocar e segurar, depois de cerca de um segundo de manter o dedo, o gesto será promovido para uma espera e um toque não ocorrerá mais.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-309">If you request both Tap and Hold, after about a second of holding down their finger the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="9e2d9-310">Para usar o SpatialGestureRecognizer, manipule o evento [InteractionDetected](/uwp/api/Windows.UI.Input.Spatial.SpatialInteractionManager) do SpatialInteractionManager e pegue o SpatialPointerPose exposto lá.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-310">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](/uwp/api/Windows.UI.Input.Spatial.SpatialInteractionManager) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="9e2d9-311">Use o cabeçalho do usuário olhar Ray desta pose para fazer a interseção com os hologramas e as malhas de superfície no ambiente do usuário para determinar o que o usuário está pretendendo a interagir.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-311">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings to determine what the user is intending to interact with.</span></span> <span data-ttu-id="9e2d9-312">Em seguida, encaminhe o SpatialInteraction nos argumentos do evento para o SpatialGestureRecognizer do holograma de destino, usando seu método [CaptureInteraction](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) .</span><span class="sxs-lookup"><span data-stu-id="9e2d9-312">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) method.</span></span> <span data-ttu-id="9e2d9-313">Isso começa a interpretar essa interação de acordo com o [SpatialGestureSettings](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureSettings) definido no reconhecedor no momento da criação-ou por [TrySetGestureSettings](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer).</span><span class="sxs-lookup"><span data-stu-id="9e2d9-313">This starts interpreting that interaction according to the [SpatialGestureSettings](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer).</span></span>

<span data-ttu-id="9e2d9-314">No HoloLens (primeira gen), as interações e os gestos devem derivar seu direcionamento do olhar de cabeça do usuário, em vez de renderizar ou interagir no local da mão.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-314">On HoloLens (first gen), interactions and gestures should derive their targeting from the user's head gaze, rather than rendering or interacting at the hand's location.</span></span> <span data-ttu-id="9e2d9-315">Depois que uma interação for iniciada, movimentos relativos da mão poderão ser usados para controlar o gesto, assim como com o gesto de manipulação ou de navegação.</span><span class="sxs-lookup"><span data-stu-id="9e2d9-315">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="9e2d9-316">Confira também</span><span class="sxs-lookup"><span data-stu-id="9e2d9-316">See also</span></span>
* [<span data-ttu-id="9e2d9-317">Olhar fixo com cabeça e olhos no DirectX</span><span class="sxs-lookup"><span data-stu-id="9e2d9-317">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="9e2d9-318">Modelo de entrada de manipulação direta</span><span class="sxs-lookup"><span data-stu-id="9e2d9-318">Direct manipulation input model</span></span>](../../design/direct-manipulation.md)
* [<span data-ttu-id="9e2d9-319">Modelo de entrada de ponto e confirmação</span><span class="sxs-lookup"><span data-stu-id="9e2d9-319">Point-and-commit input model</span></span>](../../design/point-and-commit.md)
* [<span data-ttu-id="9e2d9-320">Olhar e confirmar modelo de entrada</span><span class="sxs-lookup"><span data-stu-id="9e2d9-320">Gaze and commit input model</span></span>](../../design/gaze-and-commit.md)
* [<span data-ttu-id="9e2d9-321">Controladores de movimentos</span><span class="sxs-lookup"><span data-stu-id="9e2d9-321">Motion controllers</span></span>](../../design/motion-controllers.md)